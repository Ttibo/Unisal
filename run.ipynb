{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(num_epochs=2, optim_algo='SGD', momentum=0.9, lr=0.04, lr_scheduler='ExponentialLR', lr_gamma=0.99, weight_decay=0.0001, cnn_weight_decay=1e-05, train_cnn_after=100, grad_clip=2.0, cnn_lr_factor=0.1, loss_metrics=['kld', 'nss', 'cc'], loss_weights=[1, -0.1, -0.1], chkpnt_warmup=2, chkpnt_epochs=2, path_save='./weights/video_test/', path_dataset='C:/Users/Shadow/Documents/Dataset/Packaging_delta_1_sigma_20/')\n",
      "Move model to torch device set to: mps\n",
      "Path: /Users/coconut/Documents/Dataset/GenSaliency/VisualSaliency/ittention_videos//train/\n",
      "Numbers videos 59\n",
      "Path: /Users/coconut/Documents/Dataset/GenSaliency/VisualSaliency/ittention_videos//val/\n",
      "Numbers videos 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "import dataloaders\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "import utils\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEFAULT_DEVICE = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEFAULT_DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEFAULT_DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Créez un parser d'arguments\n",
    "parser = argparse.ArgumentParser(description='Trainer for the model.')\n",
    "\n",
    "# Ajoutez les arguments pour le Trainer\n",
    "parser.add_argument('--num_epochs', type=int, default=2, help='Nombre d\\'époques pour l\\'entraînement.')\n",
    "parser.add_argument('--optim_algo', type=str, default=\"SGD\", help='Algorithme d\\'optimisation.')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='Momentum pour l\\'optimiseur.')\n",
    "parser.add_argument('--lr', type=float, default=0.04, help='Taux d\\'apprentissage.')\n",
    "parser.add_argument('--lr_scheduler', type=str, default=\"ExponentialLR\", help='Type de planificateur de taux d\\'apprentissage.')\n",
    "parser.add_argument('--lr_gamma', type=float, default=0.99, help='Facteur gamma pour le planificateur de taux d\\'apprentissage.')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4, help='Poids de décroissance pour l\\'optimiseur.')\n",
    "parser.add_argument('--cnn_weight_decay', type=float, default=1e-5, help='Poids de décroissance pour le CNN.')\n",
    "parser.add_argument('--train_cnn_after', type=int, default=100, help='Nombres epochs pour commencer à entrainer l encoder')\n",
    "parser.add_argument('--grad_clip', type=float, default=2.0, help='Valeur de coupure de gradient.')\n",
    "parser.add_argument('--cnn_lr_factor', type=float, default=0.1, help='Facteur de taux d\\'apprentissage pour le CNN.')\n",
    "parser.add_argument('--loss_metrics', type=str, nargs='+', default=[\"kld\", \"nss\", \"cc\"], help='Métriques de perte à utiliser.')\n",
    "parser.add_argument('--loss_weights', type=float, nargs='+', default=[1, -0.1, -0.1], help='Poids des métriques de perte.')\n",
    "parser.add_argument('--chkpnt_warmup', type=int, default=2, help='Époques de montée en température pour le point de contrôle.')\n",
    "parser.add_argument('--chkpnt_epochs', type=int, default=2, help='Nombre d\\'époques pour sauvegarder le point de contrôle.')\n",
    "parser.add_argument('--path_save', type=str, default=\"./weights/video_test/\" , help='path save output')\n",
    "parser.add_argument('--path_dataset', type=str, default=\"C:/Users/Shadow/Documents/Dataset/Packaging_delta_1_sigma_20/\" , help='path dataset')\n",
    "\n",
    "# Analysez les arguments\n",
    "args = parser.parse_args('')\n",
    "print(args)\n",
    "# create model Unisal\n",
    "unisal_ = model.UNISAL(bypass_rnn=False)\n",
    "\n",
    "# load model from github and res\n",
    "directory_ = \"./weights/weights_best.pth\"\n",
    "unisal_.load_weights(directory_ )\n",
    "# move model to device\n",
    "print(f\"Move model to torch device set to: {DEFAULT_DEVICE}\")\n",
    "unisal_.to(DEFAULT_DEVICE)\n",
    "\n",
    "packaging_train = dataloaders.PACKAGINGDataset(path=\"/Users/coconut/Documents/Dataset/GenSaliency/VisualSaliency/Packaging_delta_3_sigma_20/\" + \"/train/\")\n",
    "packaging_val = dataloaders.PACKAGINGDataset(path=\"/Users/coconut/Documents/Dataset/GenSaliency/VisualSaliency/Packaging_delta_3_sigma_20/\" + \"/val/\")\n",
    "\n",
    "video_train = dataloaders.VideoDataset(path= \"/Users/coconut/Documents/Dataset/GenSaliency/VisualSaliency/ittention_videos/\" + \"/train/\", N = 12)\n",
    "video_val = dataloaders.VideoDataset(path=\"/Users/coconut/Documents/Dataset/GenSaliency/VisualSaliency/ittention_videos/\" + \"/val/\", N=12)\n",
    "\n",
    "# print(\"Len Dataset : {}\".format(len(packaging_)))\n",
    "\n",
    "dataloaders_ = [\n",
    "# {\n",
    "#     'name' : 'Packaging',\n",
    "#     'loader' : {\n",
    "#         'train' : DataLoader(packaging_train, batch_size=10, shuffle=True),\n",
    "#         'val' : DataLoader(packaging_val, batch_size=10, shuffle=True)\n",
    "#     }\n",
    "# },\n",
    "{\n",
    "    'name' : 'Video',\n",
    "    'loader' : {\n",
    "        'train' : DataLoader(video_train, batch_size=4, shuffle=True),\n",
    "        'val' : DataLoader(video_val, batch_size=4, shuffle=True)\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   0, lr 0.04000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing:  13%|█▎        | 2/15 [00:08<00:57,  4.42s/Batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instanciez le Trainer avec les arguments\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m     dataloaders\u001b[38;5;241m=\u001b[39mdataloaders_,  \u001b[38;5;66;03m# Remplacez ceci par vos dataloaders\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     device\u001b[38;5;241m=\u001b[39mDEFAULT_DEVICE,  \u001b[38;5;66;03m# Ou tout autre dispositif\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     train_cnn_after\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_cnn_after\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Prive/Unisal/trainer.py:107\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphases:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Save a checkpoint if applicable\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchkpnt_warmup\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchkpnt_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    113\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Prive/Unisal/trainer.py:145\u001b[0m, in \u001b[0;36mTrainer.fit_phase\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloader\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch processing\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ix_ , sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloader\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase]):\n\u001b[0;32m--> 145\u001b[0m         loss, loss_summands, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_clip\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m         running_losses[loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[1;32m    151\u001b[0m         running_loss_summands[loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    152\u001b[0m             r \u001b[38;5;241m+\u001b[39m l \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m r, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(running_loss_summands[loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]], loss_summands)\n\u001b[1;32m    154\u001b[0m         ]\n",
      "File \u001b[0;32m~/Documents/Prive/Unisal/trainer.py:224\u001b[0m, in \u001b[0;36mTrainer.fit_sample\u001b[0;34m(self, sample, grad_clip)\u001b[0m\n\u001b[1;32m    221\u001b[0m         param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Run forward pass\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m pred_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# pred_seq = self.model(x)\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Compute the total loss\u001b[39;00m\n\u001b[1;32m    228\u001b[0m loss_summands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_sequences(\n\u001b[1;32m    229\u001b[0m     pred_seq, sal, fix, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_metrics\n\u001b[1;32m    230\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/unisal/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/unisal/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Prive/Unisal/model/unisal.py:563\u001b[0m, in \u001b[0;36mUNISAL.forward\u001b[0;34m(self, x, target_size, h0, return_hidden, source, static)\u001b[0m\n\u001b[1;32m    558\u001b[0m im_feat \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(im_feat, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmoothing_ksize \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    559\u001b[0m im_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoothing\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (source_str \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_smoothing \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    561\u001b[0m )(im_feat)\n\u001b[0;32m--> 563\u001b[0m im_feat \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mim_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    565\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m im_feat \u001b[38;5;241m=\u001b[39m log_softmax(im_feat)\n\u001b[1;32m    568\u001b[0m output_seq\u001b[38;5;241m.\u001b[39mappend(im_feat)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/unisal/lib/python3.9/site-packages/torch/nn/functional.py:4087\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   4081\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mare_deterministic_algorithms_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[1;32m   4082\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001b[39;00m\n\u001b[1;32m   4083\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   4084\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   4085\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_upsample_linear_vec(\n\u001b[1;32m   4086\u001b[0m                 \u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 4087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample_bilinear2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instanciez le Trainer avec les arguments\n",
    "trainer = Trainer(\n",
    "    dataloaders=dataloaders_,  # Remplacez ceci par vos dataloaders\n",
    "    device=DEFAULT_DEVICE,  # Ou tout autre dispositif\n",
    "    model=unisal_,  # Remplacez ceci par votre modèle\n",
    "    path=args.path_save,  # Remplacez ceci par le chemin vers les points de contrôle\n",
    "    num_epochs=args.num_epochs,\n",
    "    optim_algo=args.optim_algo,\n",
    "    momentum=args.momentum,\n",
    "    lr=args.lr,\n",
    "    lr_scheduler=args.lr_scheduler,\n",
    "    lr_gamma=args.lr_gamma,\n",
    "    weight_decay=args.weight_decay,\n",
    "    cnn_weight_decay=args.cnn_weight_decay,\n",
    "    grad_clip=args.grad_clip,\n",
    "    cnn_lr_factor=args.cnn_lr_factor,\n",
    "    loss_metrics=args.loss_metrics,\n",
    "    loss_weights=args.loss_weights,\n",
    "    chkpnt_warmup=args.chkpnt_warmup,\n",
    "    chkpnt_epochs=args.chkpnt_epochs,\n",
    "    train_cnn_after=args.train_cnn_after\n",
    ")\n",
    "\n",
    "trainer.fit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unisal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
